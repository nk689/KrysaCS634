{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c0603c-6a66-4968-b226-22339f189a54",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:3em;color:blue\">CS634 Final Project</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b7801-69d6-4591-b4a6-78e5312bcaca",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:2.2em\">by Nicole Krysa</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79224add-1472-45e7-93e5-4c725712092c",
   "metadata": {},
   "source": [
    "<h5>July 12th, 2024</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ab1445-68c9-4646-a796-47fc9fa3a9db",
   "metadata": {},
   "source": [
    "<h3>1. Goal of Project</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d939376b-f506-44f3-9ae7-05fcc2c67031",
   "metadata": {},
   "source": [
    "<p>The goal of this project was to explore different algorithms in data mining by implementing python packages, and evaluating the different classifiers using different parameters.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5faccf8-f23d-40ec-81b4-8e5547b765b8",
   "metadata": {},
   "source": [
    "<h4>1.1 Data Source</h4>\n",
    "<p>The data I used for my project can be found at the website <a href = \"https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators\">here</a>.</p>\n",
    "<p>The documentation for UC Irvine's Machine Learning Repository can be found <a href = \"https://github.com/uci-ml-repo/ucimlrepo\">here</a></p>\n",
    "<p>The data contains survey information from patients and if they are diabetic, pre-diabetic, or not. To make the models binary classification, my program classifies patients that are diabetic and pre-diabetic into one category, simplifying it into 2 class labels.\n",
    "    There are 253,680 instances of data in the dataset, with 21 features.\n",
    "    The features are:\n",
    "    <ol>\n",
    "    <li>High Blood Pressure (Binary)</li>\n",
    "    <li>High Cholesterol (Binary)</li>\n",
    "    <li>Cholesterol Check in the past 5 years (Binary)</li>\n",
    "    <li>BMI (Integer)</li>\n",
    "    <li>Smoker (Binary)</li>\n",
    "    <li>Stroke (Binary)</li>\n",
    "    <li>Heart Disease / Attack (Binary)</li>\n",
    "    <li>Physically Active (Binary)</li>\n",
    "    <li>Fruits in Diet (Binary)</li>\n",
    "    <li>Vegetables in Diet (Binary)</li>\n",
    "    <li>Heavy Alcohol Consumption (Binary)</li>\n",
    "    <li>Healthcare (Binary)</li>\n",
    "    <li>Did not see a Doctor because of cost (Binary)</li>\n",
    "    <li>General Health (Integer)</li>\n",
    "    <li>Mental Health (Integer)</li>\n",
    "    <li>Physical Health (Integer)</li>\n",
    "    <li>Difficulty Walking (Binary)</li>\n",
    "    <li>Sex (Binary)</li>\n",
    "    <li>Age (Integer)</li>\n",
    "    <li>Education (Integer)</li>\n",
    "    <li>Income (Integer)</li>\n",
    "    </ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554be583-22b3-4bcb-801b-23f23e19b8a0",
   "metadata": {},
   "source": [
    "<h3>2. Setup</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabbd571-c8d4-42bb-abd7-850126b6c751",
   "metadata": {},
   "source": [
    "<h4>2.1 Installation</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc473bff-5cd5-400b-b2bc-6642a090c5c8",
   "metadata": {},
   "source": [
    "<p><ol>\n",
    "    <li>Install python: This is the language used for my code</li>\n",
    "    <li>Install tensorflow: This library containts software for high performance data analysis and machine learning</li>\n",
    "    <li>Install pandas: This library contains data analysis tools in Python</li>\n",
    "    <li>Install tabulate: This is used to display results in tabular format</li>\n",
    "    <li>Install scikit-learn: This module contains tools for data analysis and machine learning in Python</li>\n",
    "    <li>Install ucimlrepo: This module installs code to load the dataset from the UCI ML Repository</li>\n",
    "</ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266fbef9-fc41-4f49-8027-0d1f605ca0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python # install python\n",
    "pip install tensorflow # install tensorflow\n",
    "pip install pandas # install pandas\n",
    "pip install tabulate # install tabulate\n",
    "pip install scikit-learn #install skt\n",
    "pip install ucimlrepo #install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134cd32-9bae-4076-a4e4-258d043c3a0d",
   "metadata": {},
   "source": [
    "<h4>2.2 Imports</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9533989-73a5-47b1-a673-02b19b093c3b",
   "metadata": {},
   "source": [
    "<h5>General</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c7e5b-cf90-4f6b-9733-744fc67271b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "try:\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "except Exception as e:\n",
    "    print('')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd8d74b-4288-49e6-bcdb-4a8fb6fac931",
   "metadata": {},
   "source": [
    "<h5>Loading Data</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1150515e-4902-4b3a-b6dd-ac7c04481cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd6656-a7c1-4530-8844-fde8bad28ea5",
   "metadata": {},
   "source": [
    "<h5>KFold</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b09b2c63-7f0c-4b7c-b7b0-ce60312b7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac0aef5-8367-45d8-b9c7-9308d1879912",
   "metadata": {},
   "source": [
    "<h5>LSTM</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf759931-3c80-4baa-bc28-a7907cc85402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e339c313-8128-41e5-b5e7-b58e8c74cf53",
   "metadata": {},
   "source": [
    "<h5>Random Forest</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b1d1ed-3533-4b06-bfa8-52e553099390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51699cf-be5c-4231-8417-75b0841bb815",
   "metadata": {},
   "source": [
    "<h5>Gaussian Naive Bayes</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0e278-a2f8-4935-9f6e-e81bb73a33ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757d8d51-b9df-46e2-8059-76821e23e5f5",
   "metadata": {},
   "source": [
    "<h4>2.3 Loading Data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7a1fe0-dbc1-40a8-989d-7eb9c492dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and split dataset into features and targets\n",
    "cdc_diabetes_health_indicators = fetch_ucirepo(id=891) \n",
    "X = cdc_diabetes_health_indicators.data.features \n",
    "y = cdc_diabetes_health_indicators.data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8994afa0-a9b6-42e0-9a37-7bfe1dd951d3",
   "metadata": {},
   "source": [
    "<h4>2.4 Splitting Data</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed55b90-32e4-4f8c-9902-6e49b18a48cd",
   "metadata": {},
   "source": [
    "<p>Cross-validation is a tool used to evaluate model performance, by splitting the dataset into k partitions and choosing one at a time as the test group, while using the rest of the data as the training group. For 10-fold cross validation, the dataset is split into 10 groups, and the process is repeated 10 times. 10-fold is used because it generally more accurate while keeping computation costs lower, and relatively low bias and variance.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51b9121c-ae00-42c8-867e-c1cc71ac70b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m kf \u001b[38;5;241m=\u001b[39m KFold(n_splits \u001b[38;5;241m=\u001b[39m numSplits, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 10 iterations  of 10-fold \u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (trainIndex, testIndex) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kf\u001b[38;5;241m.\u001b[39msplit(\u001b[43mX\u001b[49m), start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;66;03m# Splitting the data into training sets and test sets\u001b[39;00m\n\u001b[0;32m      8\u001b[0m   XTrain, XTest \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[trainIndex], X\u001b[38;5;241m.\u001b[39miloc[testIndex]\n\u001b[0;32m      9\u001b[0m   yTrain, yTest \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[trainIndex], y\u001b[38;5;241m.\u001b[39miloc[testIndex]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# K-Fold separation into 10 folds\n",
    "numSplits = 10\n",
    "kf = KFold(n_splits = numSplits, shuffle = True, random_state = 42)\n",
    "\n",
    "# 10 iterations  of 10-fold \n",
    "for i, (trainIndex, testIndex) in enumerate(kf.split(X), start = 1):\n",
    "  # Splitting the data into training sets and test sets\n",
    "  XTrain, XTest = X.iloc[trainIndex], X.iloc[testIndex]\n",
    "  yTrain, yTest = y.iloc[trainIndex], y.iloc[testIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166384a1-c136-45fd-9c28-88e0ce54c00f",
   "metadata": {},
   "source": [
    "<h4>3. Calculations</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2167df45-868f-4193-a9a5-d7d9313423ed",
   "metadata": {},
   "source": [
    "<h5>3.1 Metric Calculations</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c76901-0a05-47ea-a95e-d934fa73291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the confusion matrix\n",
    "def calculate_results(cm):\n",
    "\n",
    "#Splitting confusion matrix\n",
    "  tP = cm[0][0]\n",
    "  tN = cm[1][1]\n",
    "  fP = cm[1][0]\n",
    "  fN = cm[0][1]\n",
    "  \n",
    "  P = tP + fN\n",
    "  N = tN + fP\n",
    "\n",
    "#Calculating metrics\n",
    "  sensitivity = tP / P\n",
    "  specificity = tN / N\n",
    "  precision = tP / (tP + fP)\n",
    "  accuracy = (tP + tN) / (P + N)\n",
    "  falsePositiveRate = fP / N\n",
    "  falseNegativeRate = fN / P\n",
    "  F1Measure = (2 * tP) / (2 * tP * fP * fN)\n",
    "  errorRate = (fP + fN) / (P + N)\n",
    "\n",
    "#Print results as a table\n",
    "  print(tabulate([['Accuracy', str(round(accuracy*100, 2)) + \"%\"], \n",
    "                  ['Sensitivity (Recall)', str(round(sensitivity*100, 2)) + \"%\"], \n",
    "                  ['Specificity', str(round(specificity*100, 2)) + \"%\"], \n",
    "                  ['Precision', str(round(precision*100, 2)) + \"%\"], \n",
    "                  ['False Positive Rate', str(round(falsePositiveRate*100, 2)) + \"%\"], \n",
    "                  ['False Negative Rate', str(round(falseNegativeRate*100, 2)) + \"%\"], \n",
    "                  ['Error Rate', str(round(errorRate*100, 2)) + \"%\\n\"]], \n",
    "                 headers = ['Measurement', 'Percent'], tablefmt ='orgtbl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350bcdb6-366b-42ae-b7e1-1a571c1d8f51",
   "metadata": {},
   "source": [
    "<p>One of the 10 runs is shown below.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fcb71d-393b-44d8-94c8-6cf29d6e56c7",
   "metadata": {},
   "source": [
    "<img src=\"Nicole_Krysa_CS634_FinalProject/CS634 Runs.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f98d53-0cf3-4c95-b078-9b0a4f2d346e",
   "metadata": {},
   "source": [
    "<h3>4. Classifiers</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c4969a-5027-4ad7-bd47-110001f3e268",
   "metadata": {},
   "source": [
    "<p>I chose to use Random Forest, Gaussian Naive Bayes, and LSTM classifiers.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83fa5d-21db-4e2b-b4f8-0ad6e73c22f4",
   "metadata": {},
   "source": [
    "<h4>4.1 Random Forest</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27088721-8d41-4b36-a464-376ffb2c75e4",
   "metadata": {},
   "source": [
    "<p> I chose to use the Random Forest classifier in part because it was a requirement of the project, but also because of the high accuracy of the classifier coming from multiple decision trees, it can handle larger datasets with many features (such as this one), and it is robust to outliers.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b28926-77ad-4e5f-8b01-427ae5a70271",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (741119366.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    modelRF = RandomForestClassifier(n_estimators=10, max_features = \"sqrt\")\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "  modelRF = RandomForestClassifier(n_estimators=10, max_features = \"sqrt\")\n",
    "  modelRF = modelRF.fit(XTrain, yTrain.values.ravel())\n",
    "  yPredictionsRF = modelRF.predict(XTest)\n",
    "\n",
    "# Calculating Results\n",
    "  print(\"Results of the Random Forest execution run #\" + str(i) + \"\\n\")\n",
    "  RFcm = confusion_matrix(yTest, yPredictionsRF)\n",
    "\n",
    "# Adding to a RF cumulative confusion matrix\n",
    "  tP = RFcm[0][0]\n",
    "  tN = RFcm[1][1]\n",
    "  fP = RFcm[1][0]\n",
    "  fN = RFcm[0][1]\n",
    "\n",
    "  RFTotal[0][0] += tP\n",
    "  RFTotal[1][1] += tN\n",
    "  RFTotal[1][0] += fP\n",
    "  RFTotal[0][1] += fN\n",
    "  calculate_results(RFcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c98af7d-f2e8-4cfa-bc14-b448a6d58966",
   "metadata": {},
   "source": [
    "<h4>4.2 Gaussian Naive Bayes Classifier</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25994455-1449-4020-97c3-7671b16d583f",
   "metadata": {},
   "source": [
    "<p> I chose the Gaussian Naive Bayes classifier because we learned about it early on and I had heard of Bayes' theorem in math calsses. It is relatively simple, robust to outliers. It assumes that the features are independent and the data is normally distributed. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c6d2b7-7c41-49de-bbaa-2daaec0dc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gussian Naive Bayes\n",
    "modelGNB = GaussianNB()\n",
    "  modelGNB = modelGNB.fit(XTrain, yTrain.values.ravel())\n",
    "  yPredictionsGNB = modelGNB.predict(XTest)\n",
    "\n",
    "# Calculating Results\n",
    "  print(\"Results of the Gaussian Naive-Bayes execution run #\" + str(i) + \"\\n\")\n",
    "  GNBcm = confusion_matrix(yTest, yPredictionsGNB)\n",
    "  tP = GNBcm[0][0]\n",
    "  tN = GNBcm[1][1]\n",
    "  fP = GNBcm[1][0]\n",
    "  fN = GNBcm[0][1]\n",
    "\n",
    "# Adding to a GNB cumulative confusion matrix\n",
    "  GNBTotal[0][0] += tP\n",
    "  GNBTotal[1][1] += tN\n",
    "  GNBTotal[1][0] += fP\n",
    "  GNBTotal[0][1] += fN\n",
    "  calculate_results(GNBcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ebeea2-9601-448e-b941-cb98e2cfc8c2",
   "metadata": {},
   "source": [
    "<h4>4.3 Long Short-Term Memory</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46acdd00-7812-4eca-84c1-a3dfba0e5a64",
   "metadata": {},
   "source": [
    "<p> LSTM is a deep learning algorithm, a type of recurrent neural network arcitecture designed to better retain long-term dependencies with large gaps. This is acheived with memory cells that store information for a longer time, and gates that control information flow in and out and handle new information.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76526ace-750c-4bd6-9417-ce8ae1434969",
   "metadata": {},
   "outputs": [],
   "source": [
    "  vectorLength = 32\n",
    "  topWords = len(XTrain) + len(XTest) \n",
    "  modelLSTM = Sequential()\n",
    "  modelLSTM.add(Embedding(topWords, vectorLength))\n",
    "  modelLSTM.add(LSTM(50)) # 50 memory units\n",
    "\n",
    "  # Classification problem - Use one dense final output layer with a single neuron after the LSTM layer\n",
    "  # Sigmoid activation (0, 1) for binary classifications\n",
    "  modelLSTM.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "  # Binary values - binary crossentropy\n",
    "  modelLSTM.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "  modelLSTM.fit(XTrain, yTrain, validation_data=(XTest, yTest), epochs = 1, batch_size = 500, verbose = 0)\n",
    "  scores = modelLSTM.evaluate(XTest, yTest, verbose=0)\n",
    "\n",
    "  # Flatten results to binary values\n",
    "  yPredictionsLSTM = (modelLSTM.predict(XTest) > 0.5).astype(int) \n",
    "\n",
    "  #Calculate Results\n",
    "  print(\"Results of the LSTM execution run #\" + str(i) + \"\\n\")\n",
    "  LSTMcm = confusion_matrix(yTest, yPredictionsLSTM)\n",
    "  tP = LSTMcm[0][0]\n",
    "  tN = LSTMcm[1][1]\n",
    "  fP = LSTMcm[1][0]\n",
    "  fN = LSTMcm[0][1]\n",
    "\n",
    "  # Add to a LSTM cumulative confusion matrix\n",
    "  LSTMTotal[0][0] += tP\n",
    "  LSTMTotal[1][1] += tN\n",
    "  LSTMTotal[1][0] += fP\n",
    "  LSTMTotal[0][1] += fN\n",
    "  calculate_results(LSTMcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9878df9e-bff8-49ef-8d88-83223de88cdb",
   "metadata": {},
   "source": [
    "<h4>4.4 Cumulative Results</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b33d1-35a7-46d0-9e0a-6b1d5cbc8466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Results\n",
    "print(\"Results of the overall Random Trees execution\\n\")\n",
    "calculate_results(RFTotal)\n",
    "print(\"Results of the overall Gaussian Naive Bayes execution\\n\")\n",
    "calculate_results(GNBTotal)\n",
    "print(\"Results of the overall LSTM execution\\n\")\n",
    "calculate_results(LSTMTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ae991-fc63-4648-a3be-8299b5650767",
   "metadata": {},
   "source": [
    "<img src=\"Nicole_Krysa_CS634_FinalProject/CS634 Totals.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9381141-41bc-4f77-9751-ddec5080b7ca",
   "metadata": {},
   "source": [
    "<p>There were some surprising results from the final averages for each function. </p>\n",
    "<p>Random Forest and LSTM were both airly accurate, managing consistantly classify about 85%-86% of data correctly. Random Forest had less False Positives, while LSTM had less False Negatives. Though they were close, in the case of determining if an individual has diabetes we would rather minimize the false negatives (Type II errors), so I would choose the LSTM model.</p>\n",
    "<p>Gaussian Naive Bayes did not identify diabetes as accurately as the other two, showing I may have been incorrect in assuming that the data would have a normal distribution. I also realized that the features would likely not be indipendent, as someone with one health problem may be more likely to have others as well, and this was the main focus of many of the data features. It outperformed the other two in the case of precision, identifying positive cases accurately, and specificity, meaning there were less false positives, also shown in that category. There is a tradeoff, and while this model minimizes false positives, the false negative rate was 19.35%, which is a lot of patients who actually had diabetes and were misclassified, a potentially dangerous mistake.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64b6c3e-abdc-4ec6-ac9e-a0029df1b60d",
   "metadata": {},
   "source": [
    "<h4>4.5 Classification</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e8a1b4-a533-4a63-adf5-86cb52e9d772",
   "metadata": {},
   "source": [
    "<p>The following shows two tuples being classified. The values are listed for the features (described in the beginning), and whether each model classified as the individual to have diabetes (1) or not (0). The first value is a friend who I polled, and who does not have diabetes, so it classified her correctly. The second value was from a less healthy individual, who did not have diabetes, and the Gaussian Naive Bayes model classified them as having diabetes.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df300a-8452-4c45-9c69-f2f8bacecd38",
   "metadata": {},
   "source": [
    "<img src=\"CS634 Totals.png">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
